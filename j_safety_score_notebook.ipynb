{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Safety score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import json \n",
    "\n",
    "# def calculate_safety_score(theta, t, alpha, beta, sigma, eta):\n",
    "#     if t < theta:\n",
    "#         return sigma * (alpha * (theta**2 - t**2) + beta * (theta - t))\n",
    "#     else:\n",
    "#         return eta * (alpha * (theta**2 - t**2) + beta * (theta - t))\n",
    "\n",
    "# def calculate_path_safety_score(perfect_path, driven_path, alpha, beta, sigma, eta):\n",
    "#     safety_score = 0\n",
    "#     for i in range(len(perfect_path)):\n",
    "#         theta = np.sqrt(perfect_path[i][0]**2 + perfect_path[i][1]**2)\n",
    "#         t = np.sqrt((driven_path[i][0] - perfect_path[i][0])**2 + (driven_path[i][1] - perfect_path[i][1])**2)\n",
    "#         safety_score += calculate_safety_score(theta, t, alpha, beta, sigma, eta)\n",
    "#     return safety_score\n",
    "\n",
    "# def calculate_path_safety_score_AB(perfect_path, driven_path, alpha, beta, sigma, eta, velocity, acceleration):\n",
    "#     safety_score = 0\n",
    "#     for i in range(len(perfect_path)):\n",
    "#         theta = np.sqrt(perfect_path[i][0]**2 + perfect_path[i][1]**2)\n",
    "#         t = np.sqrt((driven_path[i][0] - perfect_path[i][0])**2 + (driven_path[i][1] - perfect_path[i][1])**2)\n",
    "#         alpha_i = alpha*(1+acceleration)\n",
    "#         beta_i = beta*(1+velocity)\n",
    "#         safety_score += calculate_safety_score(theta, t, alpha_i, beta_i, sigma, eta)\n",
    "#     return safety_score\n",
    "\n",
    "\n",
    "# # Load the perfect and driven path JSON files\n",
    "# with open('user_input/scenario_0.json') as f:\n",
    "#     perfect_path_data = json.load(f)\n",
    "    \n",
    "# with open('user_input/scenario_1.json') as f:\n",
    "#     driven_path_data = json.load(f)\n",
    "\n",
    "# # Extract the vehicle locations as tuples from the JSON files\n",
    "# perfect_path = [(d['vehicle_location']['x'], d['vehicle_location']['y']) for d in perfect_path_data]\n",
    "# driven_path = [(d['vehicle_location']['x'], d['vehicle_location']['y']) for d in driven_path_data]\n",
    "\n",
    "# if len(driven_path) < len(perfect_path):\n",
    "#     last_item = driven_path[-1]\n",
    "#     driven_path += [last_item] * (len(perfect_path) - len(driven_path))\n",
    "# elif len(perfect_path) < len(driven_path):\n",
    "#     last_item = perfect_path[-1]\n",
    "#     perfect_path += [last_item] * (len(driven_path) - len(perfect_path))\n",
    "\n",
    "# alpha = 1 # alpha,beta - Indicating the velocity and acceleration of an AV and surrounding vehicles \n",
    "# beta = 1\n",
    "# sigma = 1 # Reward or penalty on the level of safety, when $t$ is lower or higher than $\\theta$, respectively\n",
    "# eta = 1\n",
    "# velocity = 30 # 30 km/h  velocity of vehicles around? \n",
    "# acceleration = 0.5  # 0.5 m/s^2 acceleration of vehicles around?\n",
    "# score = calculate_path_safety_score_AB(perfect_path, driven_path, alpha, beta, sigma, eta, velocity, acceleration)\n",
    "# print(\"Safety score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "from dtw import *\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "rated_objects = []\n",
    "count = 0\n",
    "for root, dirs, files in os.walk('user_input'):\n",
    "    for file in files:\n",
    "        if 'auto_scenario' in file:\n",
    "            count += 1\n",
    "            print(f'There are {count} files with \"auto_scenario\" in their name.')\n",
    "            \n",
    "            # Extract the number from the file name\n",
    "            scenario_num = int(file.split('_')[-1].split('.')[0])\n",
    "            \n",
    "            # Open the corresponding route file\n",
    "            with open(f'user_input/route_{scenario_num}.json', 'r') as f:\n",
    "                trajectory = json.load(f)\n",
    "\n",
    "            with open(f'user_input/auto_scenario_{scenario_num}.json') as f:\n",
    "                driven_path_data = json.load(f)\n",
    "\n",
    "            driven_path = [(d['vehicle_location']['x'], d['vehicle_location']['y']) for d in driven_path_data]\n",
    "\n",
    "            # Plot the driven path\n",
    "            plt.plot(*zip(*driven_path), label='Driven path')\n",
    "\n",
    "            # Extract the X and Y coordinates from each location\n",
    "            x_coords = [location['X'] for location in trajectory]\n",
    "            y_coords = [location['Y'] for location in trajectory]\n",
    "\n",
    "            # Plot the route on a graph\n",
    "            plt.plot(x_coords, y_coords, label='Perfect trajectory')\n",
    "\n",
    "            plt.title('Driven path vs Perfect trajectory')\n",
    "            plt.xlabel('X')\n",
    "            plt.ylabel('Y')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # Initialize lists to store data\n",
    "            timestamps = []\n",
    "            velocities = []\n",
    "            throttles = []\n",
    "\n",
    "            # Extract values from data\n",
    "            game_time = [entry['game_time'] for entry in driven_path_data]\n",
    "            velocity = [entry['vehicle_velocity']['x'] for entry in driven_path_data]\n",
    "            throttle = [entry['vehicle_throttle'] for entry in driven_path_data]\n",
    "\n",
    "            # Calculate average velocity\n",
    "            avg_velocity = np.mean(velocity)\n",
    "            # print(f'Average velocity: {avg_velocity:.2f} m/s')\n",
    "\n",
    "            # # Plot velocity over time\n",
    "            # plt.plot(game_time, velocity)\n",
    "            # plt.xlabel('Time (s)')\n",
    "            # plt.ylabel('Velocity (m/s)')\n",
    "            # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            def rate_driven_path(trajectory, driven_path, avg_velocity, num_collisions):\n",
    "                # Calculate the DTW distance between the trajectory and driven path\n",
    "                distance, _ = fastdtw(trajectory, driven_path, dist=euclidean)\n",
    "                \n",
    "                print(\"DTW: \"+str(distance))\n",
    "                # Calculate the safety score based on DTW distance and average velocity\n",
    "                safety_score = max(0, 1000 - distance - avg_velocity)\n",
    "                \n",
    "                # Penalize for number of collisions\n",
    "                safety_score -= num_collisions * (0.95**num_collisions)\n",
    "                \n",
    "                print(\"Safety score: \"+str(safety_score))\n",
    "                return safety_score\n",
    "\n",
    "            perfect_trajectory_array = list(zip(x_coords, y_coords))\n",
    "            driven_path_array = np.array(driven_path)\n",
    "\n",
    "            calculated_score = rate_driven_path(perfect_trajectory_array, driven_path_array,avg_velocity,10)\n",
    "            print(f'Calculated score: {calculated_score:.2f}')\n",
    "\n",
    "            # Open the file for reading\n",
    "            with open('user_input/scenarios.json', 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            print(f'There are {len(data)} generated scenarios')\n",
    "            \n",
    "           \n",
    "            # Find the object with the desired scenario_num\n",
    "            for obj in data:\n",
    "                if obj['scenario_num'] == scenario_num:\n",
    "                    # Add the new variable\n",
    "                    obj['calculate_score'] = calculated_score  # Replace 0 with your desired value\n",
    "                    rated_objects.append(obj)\n",
    "\n",
    "# Open the file for writing\n",
    "with open('user_input/rated_scenarios.json', 'w') as f:\n",
    "    json.dump(rated_objects, f,indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 212765.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikitich/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['3', '7', '5'] in column 6 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m     le, ohe \u001b[39m=\u001b[39m encoders[i]\n\u001b[1;32m     90\u001b[0m     X_unrated[:, i] \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mtransform(X_unrated[:, i])\n\u001b[0;32m---> 91\u001b[0m X_unrated \u001b[39m=\u001b[39m ohe\u001b[39m.\u001b[39;49mtransform(X_unrated)\n\u001b[1;32m     93\u001b[0m \u001b[39m# Make predictions on unrated scenarios\u001b[39;00m\n\u001b[1;32m     94\u001b[0m y_pred_unrated \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mpredict(X_unrated)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:882\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[39m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[1;32m    878\u001b[0m warn_on_unknown \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_unknown \u001b[39min\u001b[39;00m {\n\u001b[1;32m    879\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    880\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfrequent_if_exist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    881\u001b[0m }\n\u001b[0;32m--> 882\u001b[0m X_int, X_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(\n\u001b[1;32m    883\u001b[0m     X,\n\u001b[1;32m    884\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[1;32m    885\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    886\u001b[0m     warn_on_unknown\u001b[39m=\u001b[39;49mwarn_on_unknown,\n\u001b[1;32m    887\u001b[0m )\n\u001b[1;32m    888\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_infrequent_categories(X_int, X_mask)\n\u001b[1;32m    890\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X_int\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:160\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m handle_unknown \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    156\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    157\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound unknown categories \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m in column \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m during transform\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(diff, i)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['3', '7', '5'] in column 6 during transform"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Load data from JSON file\n",
    "with open('user_input/rated_scenarios.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = []\n",
    "y = []\n",
    "for obj in data:\n",
    "    X.append([\n",
    "        obj['weather'],\n",
    "        obj['vehicle'],\n",
    "        obj['traffic'],\n",
    "        obj['emergency'],\n",
    "        obj['timeOfDay'],\n",
    "        obj['location'],\n",
    "        obj['intersections'],\n",
    "        int(obj['pedestrians']),\n",
    "        int(obj['pedestrian_cross']),\n",
    "        obj['start_x'],\n",
    "        obj['start_y'],\n",
    "        obj['end_x'],\n",
    "        obj['end_y'],\n",
    "        obj['route_length'],\n",
    "        \n",
    "    ])\n",
    "    y.append(obj['calculate_score'])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = [0, 1, 2, 3, 4, 5]\n",
    "encoders = []\n",
    "for i in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    X[:, i] = le.fit_transform(X[:, i])\n",
    "    encoders.append((le, ohe))\n",
    "X = ohe.fit_transform(X)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Train neural network regressor\n",
    "nn = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = nn.predict(X_test)\n",
    "\n",
    "# Evaluate model performance (e.g. using mean squared error)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {mse:.2f}')\n",
    "\n",
    "# Load data from JSON file\n",
    "with open('user_input/scenarios.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract features\n",
    "X_unrated = []\n",
    "for obj in data:\n",
    "    X_unrated.append([\n",
    "        obj['weather'],\n",
    "        obj['vehicle'],\n",
    "        obj['traffic'],\n",
    "        obj['emergency'],\n",
    "        obj['timeOfDay'],\n",
    "        obj['location'],\n",
    "        obj['intersections'],\n",
    "        int(obj['pedestrians']),\n",
    "        int(obj['pedestrian_cross']),\n",
    "        obj['start_x'],\n",
    "        obj['start_y'],\n",
    "        obj['end_x'],\n",
    "        obj['end_y'],\n",
    "        obj['route_length']\n",
    "    ])\n",
    "X_unrated = np.array(X_unrated)\n",
    "\n",
    "# Encode categorical features\n",
    "for i in categorical_features:\n",
    "    le, ohe = encoders[i]\n",
    "    X_unrated[:, i] = le.transform(X_unrated[:, i])\n",
    "X_unrated = ohe.transform(X_unrated)\n",
    "\n",
    "# Make predictions on unrated scenarios\n",
    "y_pred_unrated = nn.predict(X_unrated)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic time warping\n",
    "Dynamic time warping (DTW) is an algorithm for measuring similarity between two temporal sequences, which may vary in speed. \n",
    "For instance, similarities in walking could be detected using DTW, even if one person was walking faster than the other, \n",
    "or if there were accelerations and decelerations during the course of an observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dtw import *\n",
    "\n",
    "# Load the perfect and driven path JSON files\n",
    "with open('user_input/auto_scenario_0.json') as f:\n",
    "    perfect_path_data = json.load(f)\n",
    "    \n",
    "with open('user_input/manual_scenario_0.json') as f:\n",
    "    driven_path_data = json.load(f)\n",
    "\n",
    "# Extract the vehicle locations as tuples from the JSON files\n",
    "perfect_path = [(d['vehicle_location']['x'], d['vehicle_location']['y']) for d in perfect_path_data]\n",
    "driven_path = [(d['vehicle_location']['x'], d['vehicle_location']['y']) for d in driven_path_data]\n",
    "\n",
    "# Convert the paths to numpy arrays\n",
    "perfect_path_array = np.array(perfect_path)\n",
    "driven_path_array = np.array(driven_path)\n",
    "\n",
    "# Define a distance function to use with DTW (here, we use Euclidean distance)\n",
    "def distance_func(x, y):\n",
    "    return np.linalg.norm(np.array(x) - np.array(y))\n",
    "\n",
    "# Compute the similarity value using DTW\n",
    "d, _, _, _ = dtw(perfect_path, driven_path, dist=distance_func)\n",
    "similarity = d\n",
    "\n",
    "print(\"DTW: \"+ str(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw import dtw\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    distance = 0\n",
    "    for i in range(len(point1)):\n",
    "        distance += (point1[i] - point2[i]) ** 2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "# Extract the vehicle locations as tuples from the JSON files\n",
    "perfect_path = [(d['vehicle_location']['x'], d['vehicle_location']['y']) for d in perfect_path_data]\n",
    "driven_path = [(d['vehicle_location']['x'], d['vehicle_location']['y']) for d in driven_path_data]\n",
    "\n",
    "# Convert the paths to numpy arrays\n",
    "perfect_path_array = np.array(perfect_path)\n",
    "driven_path_array = np.array(driven_path)\n",
    "\n",
    "# Calculate the DTW distance between the two paths\n",
    "distance,_,_,_= dtw(perfect_path_array, driven_path_array,dist=euclidean_distance)\n",
    "\n",
    "# Print the DTW distance\n",
    "print(\"DTW distance:\", distance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths plotted as graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the perfect and driven path JSON files\n",
    "with open('user_input/auto_scenario_0.json') as f:\n",
    "    perfect_path_data = json.load(f)\n",
    "    \n",
    "with open('user_input/manual_scenario_0.json') as f:\n",
    "    driven_path_data = json.load(f)\n",
    "\n",
    "# Extract the vehicle locations as tuples from the JSON files\n",
    "perfect_path = [(d['vehicle_location']['x'], d['vehicle_location']['y']) for d in perfect_path_data]\n",
    "driven_path = [(d['vehicle_location']['x'], d['vehicle_location']['y']) for d in driven_path_data]\n",
    "\n",
    "# Plot the perfect path\n",
    "plt.plot(*zip(*perfect_path))\n",
    "plt.title('Auto Driven path')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n",
    "\n",
    "# Plot the driven path\n",
    "plt.plot(*zip(*driven_path))\n",
    "plt.title('Manual Driven path')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n",
    "\n",
    "# Plot both paths on the same graph\n",
    "plt.plot([x for x, y in perfect_path], [y for x, y in perfect_path], 'b-', label='Perfect path')\n",
    "plt.plot([x for x, y in driven_path], [y for x, y in driven_path], 'r-', label='Driven path')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Velocity over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from JSON file\n",
    "with open('user_input/manual_scenario_0.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize lists to store data\n",
    "timestamps = []\n",
    "velocities = []\n",
    "throttles = []\n",
    "\n",
    "# Extract values from data\n",
    "game_time = [entry['game_time'] for entry in data]\n",
    "velocity = [entry['vehicle_velocity']['x'] for entry in data]\n",
    "throttle = [entry['vehicle_throttle'] for entry in data]\n",
    "\n",
    "# Plot velocity over time\n",
    "plt.plot(game_time, velocity)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Velocity (m/s)')\n",
    "plt.show()\n",
    "\n",
    "# Plot throttle over time\n",
    "plt.plot(game_time, throttle)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Throttle')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
